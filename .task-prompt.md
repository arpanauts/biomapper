# Task: Complete Refactoring of Remaining MappingExecutor Tests
# Task: Fix Failing Integration Tests Due to Configuration Issues
# Task: Implement Unit Tests for the CacheManager Service

## 1. Objective

Complete the refactoring of the `MappingExecutor` unit tests by addressing the files that were skipped during the initial effort. The goal is to migrate all remaining legacy tests to the new service-oriented architecture, ensuring full test coverage is restored.
Resolve the 20 failing integration tests by fixing the underlying test data and configuration problems. The tests have already been updated to be compatible with the new service-oriented API, but they are failing because of issues in the test environment itself.
Create a new, comprehensive suite of unit tests for the `CacheManager` service. The original cache-related tests were part of the monolithic `MappingExecutor` tests and were removed during refactoring, with the intention of creating a dedicated test suite for the new service.

## 2. Context and Background

The initial refactoring of `MappingExecutor` tests (`2025-06-22-000233-feedback-refactor-core-executor-tests.md`) successfully migrated the most critical tests but deferred work on several files due to time constraints. This task is to complete that work, bringing the entire test suite up to date with the new architecture.
The feedback from the integration test refactoring (`2025-06-22-000236-feedback-refactor-integration-tests.md`) clearly states that while API compatibility is fixed, numerous tests are still failing. The root cause is identified as missing test data files, incorrect YAML strategy configurations, or other environment-related setup problems. This is the highest priority task to stabilize the test suite, as it will validate the end-to-end functionality of the refactored application.
The `CacheManager` service is responsible for handling the caching of mapping results to avoid redundant computations. During the core executor test refactoring (see feedback `2025-06-22-000233-feedback-refactor-core-executor-tests.md`), the tests for this functionality were deferred. A placeholder file may exist at `tests/unit/core/engine_components/test_cache_manager.py`. This task is to implement the deferred tests and ensure the `CacheManager` is robust and reliable.

## 3. Prerequisites

- The agent must be familiar with the new service-oriented architecture, including the roles of `MappingExecutor` as a facade and the various services it delegates to.
- Strong proficiency with `pytest` and `unittest.mock` is required.
- The agent must be able to analyze `pytest` error logs to identify the root cause of test failures (e.g., `FileNotFoundError`, `KeyError` from config, assertion errors from unexpected data).
- Familiarity with the project's test data structure in `tests/integration/data/` and the YAML configurations is required.
- The agent must understand the public API and purpose of the `CacheManager` service.
- Proficiency in testing stateful services and using `unittest.mock` is required.

## 4. Task Breakdown

Apply the following refactoring process to each of the target files listed below:

1.  **Analyze Existing Tests:** For each test in the file, identify why it is failing or what legacy internal method it relies on.
2.  **Determine the New Logic Location:** Identify which service now contains the business logic that the test was originally intended to cover (e.g., `MetadataQueryService`, `YamlStrategyExecutionService`, `CacheManager`).
3.  **Rewrite and Relocate the Test:**
    - If the logic is now in a service, add a new, focused test to that service's dedicated test file (e.g., `tests/unit/core/services/test_metadata_query_service.py`).
    - The new test must use dependency injection and mocking to isolate the service.
    - If the test is truly about `MappingExecutor`'s orchestration, rewrite it to mock the service dependencies and assert that the correct service methods are called.
4.  **Delete the Old Test/File:** Once the logic is covered by a new test, delete the old, failing test. If an entire test file becomes empty, delete the file.

### Target Files:

- `/home/ubuntu/Software-Engineer-AI-Agent-Atlas/biomapper/tests/core/test_mapping_executor_metadata.py`
- `/home/ubuntu/Software-Engineer-AI-Agent-Atlas/biomapper/tests/unit/core/test_mapping_executor_robust_features.py`
- `/home/ubuntu/Software-Engineer-AI-Agent-Atlas/biomapper/tests/unit/core/test_mapping_executor_utilities.py`
1.  **Run the Integration Test Suite:**
    - Execute `poetry run pytest tests/integration/` to get a baseline of the current failures.

2.  **Systematically Debug Failures:**
    - For each failing test, examine the error message.
    - **If `FileNotFoundError`:** The test is likely missing a required mock data file. Create or locate the necessary file in `tests/integration/data/`.
    - **If `KeyError` or `ValidationError`:** The issue is likely in a `mapping_strategies_config.yaml` or `protein_config.yaml` file used by the test. Verify that all keys, endpoints, and paths are correctly defined.
    - **If `AssertionError`:** The test is running but producing unexpected results. This could still be a data issue. Inspect the input data and the results to see where the discrepancy lies.

3.  **Fix Configurations and Data:**
    - Make the necessary corrections to the data files and YAML configurations.
    - Do **not** change the application code. The goal is to fix the test environment, not the code under test.

4.  **Iterate and Validate:**
    - Rerun the tests after each fix to ensure it was successful and did not introduce new regressions.
    - Continue until all integration tests are passing.
1.  **Locate or Create the Test File:**
    - Find the test file at `/home/ubuntu/Software-Engineer-AI-Agent-Atlas/biomapper/tests/unit/core/engine_components/test_cache_manager.py`. If it doesn't exist, create it.

2.  **Review the `CacheManager` Implementation:**
    - Open `biomapper/core/engine_components/cache_manager.py` to understand its public methods (e.g., `check_cache`, `cache_results`) and dependencies.

3.  **Implement Unit Tests:**
    - Create a `setup` method or fixture to initialize a `CacheManager` instance for each test.
    - **Test `check_cache`:**
        - Write a test to verify that `check_cache` returns `None` for an identifier that is not in the cache.
        - Write a test to verify that `check_cache` correctly returns the cached data for an identifier that has been previously cached.
    - **Test `cache_results`:**
        - Write a test to verify that after calling `cache_results`, the corresponding data can be retrieved by `check_cache`.
    - **Test Cache Structure:**
        - Write a test to ensure the data is cached in the expected format.
    - **Test Edge Cases:**
        - Test caching and retrieving empty results (`[]`).
        - Test caching and retrieving `None` values if that is a valid use case.

## 5. Implementation Requirements

- **Code Standards:** Follow existing code style. All new tests must be `async def` and use `pytest` and `unittest.mock`.
- **File Organization:** Place new service-level tests in their corresponding test files within `tests/unit/core/services/` or `tests/unit/core/engine_components/`.

- **Target Directories:** 
    - `tests/integration/`
    - `tests/integration/data/`
    - Any YAML configuration files used by the integration tests.
- **Code Standards:** Maintain existing file structures and formats.

- **Target File:** `/home/ubuntu/Software-Engineer-AI-Agent-Atlas/biomapper/tests/unit/core/engine_components/test_cache_manager.py`
- **Code Standards:** All tests must be `async def` and use `pytest` and `unittest.mock`. Follow existing project conventions.

## 6. Validation and Success Criteria

- **Success:** All tests in the target files are either successfully refactored and relocated, or are justifiably deleted. All new and modified tests must pass.
- **Validation Command:** Run `poetry run pytest` on any new or modified test files to ensure they pass.
- **Primary Success Criterion:** All tests in the `tests/integration/` directory pass successfully.
- **Validation Command:** `poetry run pytest tests/integration/`
- **Success:** A new test suite for `CacheManager` is created, and all tests within it pass.
- **Validation Command:** `poetry run pytest tests/unit/core/engine_components/test_cache_manager.py`

## 7. Feedback and Reporting

- Provide a list of the original test files that were modified or deleted.
- Provide a list of the new or modified test files where the refactored tests now reside.
- For each new/modified test file, provide the `diff` of the changes.
- Provide the `pytest` output for all new/modified files to confirm they pass.
- Provide a summary of the types of configuration issues you fixed (e.g., "Fixed 5 missing data files," "Corrected 3 endpoint names in strategy configs").
- Provide the final output of the `pytest tests/integration/` run showing that all tests pass.
- Provide the full content of the new `test_cache_manager.py` file.
- Provide the output of the `pytest` run to confirm all tests pass.

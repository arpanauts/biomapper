name: METABOLITE_CTS_BRIDGE_EXAMPLE
description: |
  Example strategy demonstrating the use of METABOLITE_CTS_BRIDGE action for translating
  metabolite identifiers between different formats using the Chemical Translation Service (CTS).
  
  This strategy translates HMDB IDs to InChIKeys and matches them across datasets.
  It includes caching, rate limiting, and fallback services for robust operation.

parameters:
  # Input data files
  source_dataset_file: "${DATA_DIR}/israeli10k_metabolites.tsv"
  target_dataset_file: "${DATA_DIR}/kg2c_metabolites.tsv"
  
  # Output configuration
  output_dir: "${OUTPUT_DIR}/metabolite_cts_bridge"
  
  # CTS configuration
  cache_file: "/tmp/cts_cache_israeli10k_to_kg2c.pkl"
  batch_size: 100
  confidence_threshold: 0.75

steps:
  # Step 1: Load source dataset (e.g., Israeli10k with HMDB IDs)
  - name: load_source_metabolites
    action:
      type: LOAD_DATASET_IDENTIFIERS
      params:
        file_path: "${parameters.source_dataset_file}"
        identifier_column: hmdb_normalized
        metadata_columns:
          - metabolite_name
          - platform
          - measurement_type
        output_key: israeli10k_metabolites
        delimiter: "\t"
        skip_rows: 0
    
  # Step 2: Load target dataset (e.g., KG2c with InChIKeys)
  - name: load_target_metabolites
    action:
      type: LOAD_DATASET_IDENTIFIERS
      params:
        file_path: "${parameters.target_dataset_file}"
        identifier_column: inchikey
        metadata_columns:
          - node_id
          - node_name
          - node_category
        output_key: kg2c_metabolites
        delimiter: "\t"
        skip_rows: 0
    
  # Step 3: Use CTS to bridge HMDB to InChIKey identifiers
  - name: cts_bridge_translation
    action:
      type: METABOLITE_CTS_BRIDGE
      params:
        # Input/Output configuration
        source_key: israeli10k_metabolites
        target_key: kg2c_metabolites
        output_key: cts_matched_metabolites
        
        # Identifier configuration
        source_id_column: hmdb_normalized
        source_id_type: hmdb
        target_id_column: inchikey
        target_id_type: inchikey
        
        # CTS API configuration
        batch_size: "${parameters.batch_size}"
        max_retries: 3
        timeout_seconds: 30
        
        # Caching configuration
        cache_results: true
        cache_file: "${parameters.cache_file}"
        
        # Fallback configuration
        use_fallback_services: true
        fallback_services:
          - pubchem
          - chemspider
        
        # Matching configuration
        confidence_threshold: "${parameters.confidence_threshold}"
        handle_multiple_translations: best
        
        # Error handling
        skip_on_error: true
        log_failures: true
    
  # Step 4: Export matched metabolites
  - name: export_matched_metabolites
    action:
      type: EXPORT_DATASET
      params:
        dataset_key: cts_matched_metabolites
        file_path: "${parameters.output_dir}/cts_matched_metabolites.tsv"
        file_format: tsv
        include_metadata: true
        columns:
          - source_id
          - target_id
          - confidence
          - match_type
    
  # Step 5: Generate summary statistics
  - name: generate_summary_report
    action:
      type: GENERATE_METABOLOMICS_REPORT
      params:
        datasets:
          - israeli10k_metabolites
          - kg2c_metabolites
          - cts_matched_metabolites
        output_file: "${parameters.output_dir}/cts_bridge_summary_report.html"
        include_statistics: true
        include_visualizations: true
        report_sections:
          - overview
          - translation_statistics
          - confidence_distribution
          - api_performance
          - cache_performance

# Advanced configuration example with multiple translation paths
advanced_steps:
  # Example: Chain multiple translations (HMDB -> CHEBI -> KEGG)
  - name: multi_hop_translation
    action:
      type: METABOLITE_CTS_BRIDGE
      params:
        source_key: hmdb_dataset
        target_key: chebi_dataset
        output_key: hmdb_to_chebi
        source_id_column: hmdb_id
        source_id_type: hmdb
        target_id_column: chebi_id
        target_id_type: chebi
        cache_file: "/tmp/cts_cache_hmdb_to_chebi.pkl"
        
  - name: second_hop_translation
    action:
      type: METABOLITE_CTS_BRIDGE
      params:
        source_key: hmdb_to_chebi
        target_key: kegg_dataset
        output_key: final_matched
        source_id_column: target_id  # Use output from previous step
        source_id_type: chebi
        target_id_column: kegg_compound_id
        target_id_type: kegg
        cache_file: "/tmp/cts_cache_chebi_to_kegg.pkl"

# Performance optimization example
performance_optimized:
  # Pre-warm cache with common translations
  - name: cache_prewarm
    action:
      type: METABOLITE_CTS_BRIDGE
      params:
        source_key: common_metabolites
        target_key: dummy_target
        output_key: cache_warmup
        batch_size: 200  # Larger batch for cache warming
        max_retries: 5   # More retries for reliability
        cache_results: true
        cache_file: "${parameters.cache_file}"
        
  # Use pre-warmed cache for actual matching
  - name: production_matching
    action:
      type: METABOLITE_CTS_BRIDGE
      params:
        source_key: production_source
        target_key: production_target
        output_key: production_matched
        batch_size: 50   # Smaller batch for production
        cache_results: true
        cache_file: "${parameters.cache_file}"  # Same cache file
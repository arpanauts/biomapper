#!/usr/bin/env python
"""
Simple test to verify data loading patterns work correctly,
especially for SPOKE and KG2C edge cases.
"""
import pandas as pd
from pathlib import Path

def test_dataset_loading():
    """Test loading all dataset types to verify column handling."""
    
    project_root = Path(__file__).parent
    test_data_dir = project_root / "data" / "test_data"
    
    print("ğŸ§ª Testing data loading patterns...\n")
    
    # Test 1: SPOKE - identifier column
    print("ğŸ“Š Testing SPOKE dataset:")
    spoke_file = test_data_dir / "spoke_proteins.csv"
    if spoke_file.exists():
        df = pd.read_csv(spoke_file)
        print(f"   âœ… Loaded {len(df)} rows")
        print(f"   ğŸ“‹ Columns: {list(df.columns)}")
        print(f"   ğŸ” Sample identifiers: {df['identifier'].head(3).tolist()}")
        print(f"   ğŸ“ Pattern: Bare UniProt IDs (no prefix)\n")
    
    # Test 2: KG2C - id column with prefix stripping
    print("ğŸ“Š Testing KG2C dataset:")
    kg2c_file = test_data_dir / "kg2c_proteins.csv"
    if kg2c_file.exists():
        df = pd.read_csv(kg2c_file)
        print(f"   âœ… Loaded {len(df)} rows")
        print(f"   ğŸ“‹ Columns: {list(df.columns)}")
        print(f"   ğŸ” Original IDs: {df['id'].head(3).tolist()}")
        
        # Simulate prefix stripping
        df['id_original'] = df['id']
        df['id'] = df['id'].str.replace('UniProtKB:', '', regex=False)
        print(f"   ğŸ”§ After stripping 'UniProtKB:': {df['id'].head(3).tolist()}")
        print(f"   ğŸ“ Pattern: Prefix stripped, original preserved\n")
    
    # Test 3: UKBB - UniProt column (capitalized)
    print("ğŸ“Š Testing UKBB dataset:")
    ukbb_file = test_data_dir / "ukbb_proteins.tsv"
    if ukbb_file.exists():
        df = pd.read_csv(ukbb_file, sep='\t')
        print(f"   âœ… Loaded {len(df)} rows")
        print(f"   ğŸ“‹ Columns: {list(df.columns)}")
        print(f"   ğŸ” Sample identifiers: {df['UniProt'].head(3).tolist()}")
        print(f"   ğŸ“ Pattern: Capitalized column name\n")
    
    # Test 4: HPA - uniprot column (lowercase)
    print("ğŸ“Š Testing HPA dataset:")
    hpa_file = test_data_dir / "hpa_proteins.csv"
    if hpa_file.exists():
        df = pd.read_csv(hpa_file)
        print(f"   âœ… Loaded {len(df)} rows")
        print(f"   ğŸ“‹ Columns: {list(df.columns)}")
        print(f"   ğŸ” Sample identifiers: {df['uniprot'].head(3).tolist()}")
        print(f"   ğŸ“ Pattern: Lowercase column name\n")
    
    print("ğŸ¯ Key observations:")
    print("1. âœ… SPOKE uses 'identifier' column with bare UniProt IDs")
    print("2. âœ… KG2C uses 'id' column with 'UniProtKB:' prefix that needs stripping")
    print("3. âœ… UKBB uses 'UniProt' column (capitalized)")
    print("4. âœ… HPA uses 'uniprot' column (lowercase)")
    print("5. âœ… All datasets can contain composite IDs (underscore-separated)")
    
    print("\nâœ… Data loading patterns verified!")
    print("Now you can proceed with testing the actual LOAD_DATASET_IDENTIFIERS action.")

if __name__ == "__main__":
    test_dataset_loading()